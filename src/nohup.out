/users/pgrad/gauravp/Desktop/BiometricByPass/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
1.40586 M parameters
Epoch 0, loss: 5.306459426879883
Epoch 10, loss: 5.306863784790039
Epoch 20, loss: 5.306869983673096
Epoch 30, loss: 5.30687141418457
Epoch 40, loss: 5.306872367858887
Epoch 50, loss: 5.306872367858887
Epoch 60, loss: 5.3068718910217285
Epoch 70, loss: 5.306872367858887
Epoch 80, loss: 5.306872367858887
Epoch 90, loss: 5.306872367858887
Epoch 100, loss: 5.181872367858887
Epoch 110, loss: 5.306872367858887
Epoch 120, loss: 5.306872367858887
Epoch 130, loss: 5.306872367858887
Epoch 140, loss: 5.306872367858887
Epoch 150, loss: 5.306872367858887
Epoch 160, loss: 5.181872367858887
Epoch 170, loss: 5.181872367858887
Epoch 180, loss: 5.181872367858887
Epoch 190, loss: 5.306872367858887
Epoch 200, loss: 5.306872367858887
Epoch 210, loss: 5.181872367858887
Epoch 220, loss: 5.181872367858887
Epoch 230, loss: 5.306872367858887
Epoch 240, loss: 5.181872367858887
Epoch 250, loss: 5.181872367858887
Epoch 260, loss: 5.306872367858887
Epoch 270, loss: 5.306872367858887
Epoch 280, loss: 5.306872367858887
Epoch 290, loss: 5.3068718910217285
Epoch 300, loss: 5.306872367858887
Epoch 310, loss: 5.3068718910217285
Epoch 320, loss: 5.181872367858887
Epoch 330, loss: 5.306872367858887
Epoch 340, loss: 5.306872367858887
Epoch 350, loss: 5.181872367858887
Epoch 360, loss: 5.181872367858887
Epoch 370, loss: 5.306872367858887
Epoch 380, loss: 5.306872367858887
Epoch 390, loss: 5.306872367858887
Epoch 400, loss: 5.306872367858887
Epoch 410, loss: 5.306872367858887
Epoch 420, loss: 5.306872367858887
Epoch 430, loss: 5.181872367858887
Epoch 440, loss: 5.306872367858887
Epoch 450, loss: 5.306872367858887
Epoch 460, loss: 5.306872367858887
Epoch 470, loss: 5.306872367858887
Epoch 480, loss: 5.306872367858887
Epoch 490, loss: 5.181872367858887
Epoch 500, loss: 5.306872367858887
Epoch 510, loss: 5.181872367858887
Epoch 520, loss: 5.306872367858887
Epoch 530, loss: 5.306872367858887
Epoch 540, loss: 5.181872367858887
Epoch 550, loss: 5.306872367858887
Epoch 560, loss: 5.306872367858887
Epoch 570, loss: 5.181872367858887
Epoch 580, loss: 5.181872367858887
Epoch 590, loss: 5.306872367858887
Epoch 600, loss: 5.306872367858887
Epoch 610, loss: 5.306872367858887
Epoch 620, loss: 5.306872367858887
Epoch 630, loss: 5.306872367858887
Epoch 640, loss: 5.306872367858887
Epoch 650, loss: 5.306872367858887
Epoch 660, loss: 5.306872367858887
Epoch 670, loss: 5.181872367858887
Epoch 680, loss: 5.181872367858887
Epoch 690, loss: 5.306872367858887
Epoch 700, loss: 5.306872367858887
Epoch 710, loss: 5.306872367858887
Epoch 720, loss: 5.306872367858887
Epoch 730, loss: 5.306872367858887
Epoch 740, loss: 5.306872844696045
Epoch 750, loss: 5.306872367858887
Epoch 760, loss: 5.306872367858887
Epoch 770, loss: 5.306872367858887
Epoch 780, loss: 5.181872367858887
Epoch 790, loss: 5.306872367858887
Epoch 800, loss: 5.306872367858887
Epoch 810, loss: 5.306872367858887
Epoch 820, loss: 5.181872367858887
Epoch 830, loss: 5.306872367858887
Epoch 840, loss: 5.306872367858887
Epoch 850, loss: 5.306872367858887
Epoch 860, loss: 5.181872367858887
Epoch 870, loss: 5.306872367858887
Epoch 880, loss: 5.306872367858887
Epoch 890, loss: 5.306872367858887
Epoch 900, loss: 5.306872367858887
Epoch 910, loss: 5.306872367858887
Epoch 920, loss: 5.306872367858887
Epoch 930, loss: 5.306872367858887
Epoch 940, loss: 5.306872367858887
Epoch 950, loss: 5.306872367858887
Epoch 960, loss: 5.306872367858887
Epoch 970, loss: 5.181872367858887
Epoch 980, loss: 5.306872367858887
Epoch 990, loss: 5.306872367858887
Accuracy on test dataset: 2.10%
